{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Qa6NPe_0QW0UU5Q23gASg22qqkdA_GlC",
      "authorship_tag": "ABX9TyNIlu0y+C6IUmWETRYClniC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonysarre/extract/blob/main/FutureIntern_DS_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1: Load Necessary Libraries"
      ],
      "metadata": {
        "id": "nVrEWvUJoKkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpnsBcL7lstj",
        "outputId": "5e83c77d-2f3d-41d1-9214-fa8d09291d27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n"
      ],
      "metadata": {
        "id": "f0nxnytolVdK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Load the Dataset"
      ],
      "metadata": {
        "id": "keSOVmASoS4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Future Intern/tweet/Tweets.csv\")  # Update the path accordingly\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdkN0-Yjn4jI",
        "outputId": "34837d22-f6f7-45ab-ea0d-e7f5f3f4aab3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
            "0  570306133677760513           neutral                        1.0000   \n",
            "1  570301130888122368          positive                        0.3486   \n",
            "2  570301083672813571           neutral                        0.6837   \n",
            "3  570301031407624196          negative                        1.0000   \n",
            "4  570300817074462722          negative                        1.0000   \n",
            "\n",
            "  negativereason  negativereason_confidence         airline  \\\n",
            "0            NaN                        NaN  Virgin America   \n",
            "1            NaN                     0.0000  Virgin America   \n",
            "2            NaN                        NaN  Virgin America   \n",
            "3     Bad Flight                     0.7033  Virgin America   \n",
            "4     Can't Tell                     1.0000  Virgin America   \n",
            "\n",
            "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
            "0                    NaN     cairdin                 NaN              0   \n",
            "1                    NaN    jnardino                 NaN              0   \n",
            "2                    NaN  yvonnalynn                 NaN              0   \n",
            "3                    NaN    jnardino                 NaN              0   \n",
            "4                    NaN    jnardino                 NaN              0   \n",
            "\n",
            "                                                text tweet_coord  \\\n",
            "0                @VirginAmerica What @dhepburn said.         NaN   \n",
            "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
            "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
            "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
            "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
            "\n",
            "               tweet_created tweet_location               user_timezone  \n",
            "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
            "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
            "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
            "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
            "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Data Exploration and Preprocessing"
      ],
      "metadata": {
        "id": "B-Q41PsvogrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape and columns of the dataset\n",
        "print(data.shape)\n",
        "print(data.columns)\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIksgoi8oijc",
        "outputId": "94ed851c-8b08-400f-bc6f-f5dc2ce1939f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14640, 15)\n",
            "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
            "       'negativereason', 'negativereason_confidence', 'airline',\n",
            "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
            "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
            "       'tweet_location', 'user_timezone'],\n",
            "      dtype='object')\n",
            "tweet_id                            0\n",
            "airline_sentiment                   0\n",
            "airline_sentiment_confidence        0\n",
            "negativereason                   5462\n",
            "negativereason_confidence        4118\n",
            "airline                             0\n",
            "airline_sentiment_gold          14600\n",
            "name                                0\n",
            "negativereason_gold             14608\n",
            "retweet_count                       0\n",
            "text                                0\n",
            "tweet_coord                     13621\n",
            "tweet_created                       0\n",
            "tweet_location                   4733\n",
            "user_timezone                    4820\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning - Keep only the necessary columns and remove rows with missing values\n",
        "data_cleaned = data[['text', 'airline_sentiment']].dropna()\n",
        "\n",
        "# Check for missing values in the cleaned dataset\n",
        "print(data_cleaned.isnull().sum())\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCME5vdbp7RU",
        "outputId": "25cf4a04-fc11-435e-c4d6-75d05e00ab01"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text                 0\n",
            "airline_sentiment    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Remove URLs and mentions\n",
        "    text = re.sub(r'http\\S+|www\\S+|@\\w+', '', text)\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Convert to lowercase and strip\n",
        "    text = text.lower().strip()\n",
        "    # Remove stopwords\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text"
      ],
      "metadata": {
        "id": "1s5yH4k0qDDT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the preprocessing to the text column\n",
        "data_cleaned['cleaned_text'] = data_cleaned['text'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "wEZTZOCYqS2W"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the cleaned text\n",
        "print(data_cleaned['cleaned_text'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1x4reeTqXEq",
        "outputId": "f60a4b2e-9adb-4210-a3d4-cc51a5308f4f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                 said\n",
            "1        plus youve added commercials experience tacky\n",
            "2         didnt today must mean need take another trip\n",
            "3    really aggressive blast obnoxious entertainmen...\n",
            "4                                 really big bad thing\n",
            "Name: cleaned_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction - Convert text to numerical form using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the text data into a bag-of-words representation\n",
        "X = vectorizer.fit_transform(data_cleaned['cleaned_text'])\n",
        "\n",
        "# Target variable (airline sentiment)\n",
        "y = data_cleaned['airline_sentiment']\n",
        "\n",
        "# Split the data into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys3a8sddqbGp",
        "outputId": "ec57f809-a1ec-4a87-c20a-21501b2d2bdb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7807377049180327\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.93      0.86      1889\n",
            "     neutral       0.66      0.41      0.51       580\n",
            "    positive       0.76      0.62      0.68       459\n",
            "\n",
            "    accuracy                           0.78      2928\n",
            "   macro avg       0.74      0.65      0.68      2928\n",
            "weighted avg       0.77      0.78      0.76      2928\n",
            "\n"
          ]
        }
      ]
    }
  ]
}